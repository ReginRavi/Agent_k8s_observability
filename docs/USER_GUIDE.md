# K8s Observability AI Agent - User Guide

> **Complete guide for installation, configuration, usage, and customization**

---

## ğŸ“‘ Table of Contents

1. [Quick Start](#quick-start)
2. [Installation](#installation)
3. [Configuration](#configuration)
4. [Using the Agent](#using-the-agent)
5. [Customizing Prompts](#customizing-prompts)
6. [Troubleshooting](#troubleshooting)
7. [API Reference](#api-reference)

---

## âš¡ Quick Start

### Fastest Way to Start

```bash
cd /Users/reginravi/Documents/Agent_k8s_observability
./start.sh
```

This script automatically:
- âœ… Checks prerequisites
- âœ… Sets up virtual environment
- âœ… Installs dependencies
- âœ… Verifies configuration
- âœ… Starts the agent

### Manual 3-Step Start

```bash
# 1. Setup environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Configure (set your Gemini API key in .env)
nano .env

# 3. Start
python3 app.py
```

Agent runs on: **http://localhost:8000**

---

## ğŸ”§ Installation

### Prerequisites

**Required:**
- Python 3.9+
- Kubernetes cluster access
- Prometheus running
- Gemini API key

**Optional but recommended:**
- Loki for logs
- Alertmanager for alerts
- Grafana for visualization

### Check Prerequisites

```bash
python3 check_prerequisites.py
```

### Get Gemini API Key

1. Visit: https://makersuite.google.com/app/apikey
2. Create new API key
3. Copy it for configuration

### Install Dependencies

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install packages
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

### Environment Variables

Edit `.env` file:

```bash
# Required
GEMINI_API_KEY=your-api-key-here

# Observability endpoints
PROMETHEUS_URL=http://localhost:9090
LOKI_URL=http://localhost:3100
ALERTMANAGER_URL=http://localhost:9093

# Kubernetes
IN_CLUSTER=false
KUBECONFIG_PATH=~/.kube/config

# Agent settings
AGENT_PORT=8000
AGENT_LOG_LEVEL=INFO
DEFAULT_LOOKBACK_MINUTES=15
```

### Minimal Configuration

Only need these to start:
```bash
GEMINI_API_KEY=your-key
PROMETHEUS_URL=http://localhost:9090
IN_CLUSTER=false
```

---

## ğŸš€ Using the Agent

### Ask Questions

#### Current/Instant Metrics
```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What is the current CPU usage?",
    "namespace": "production"
  }'
```

**Keywords for instant queries:**
- "current"
- "now"
- "right now"
- "at the moment"

#### Example Questions

**Current Metrics:**
- "What is the current CPU usage?"
- "Show me current memory for api pod"
- "What are the current metrics right now?"

**Troubleshooting:**
- "Why is my pod restarting?"
- "What's causing high CPU usage?"
- "Are there any alerts firing?"
- "Show me recent errors in logs"

**Historical Analysis:**
- "How has CPU changed in the last hour?"
- "Show memory trends over time"
- "Was there a CPU spike?"

### Using Python

```python
import httpx
import asyncio

async def ask_question(question):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/chat",
            json={"question": question, "namespace": "default"}
        )
        return response.json()

# Use it
result = asyncio.run(ask_question("What is the current CPU usage?"))
print(result['response']['answer'])
```

### Response Structure

```json
{
  "response": {
    "answer": "Detailed analysis with summary, observations, and recommendations",
    "tool_results": [
      {
        "tool_name": "metrics_instant",
        "success": true,
        "execution_time_ms": 142
      }
    ],
    "confidence": "high",
    "recommendations": [
      "Monitor api-pod as it's approaching 60% threshold",
      "Consider horizontal scaling if needed"
    ],
    "metadata": {
      "model": "gemini-3.0-pro",
      "tools_used": ["metrics_instant", "k8s_pods", "alerts"]
    }
  }
}
```

### Test Script

```bash
# Run comprehensive tests
python3 test_current_metrics.py
```

---

## ğŸ“ Customizing Prompts

All AI prompts are centralized in `prompts.py` for easy customization.

### Available Prompt Styles

```python
from prompts import get_system_prompt

# Default - comprehensive analysis
prompt = get_system_prompt("default")

# Concise - brief responses
prompt = get_system_prompt("concise")

# Detailed - thorough investigation
prompt = get_system_prompt("detailed")
```

### Configure Prompt Style

**Via environment variable:**
```bash
export PROMPT_STYLE=concise
python3 app.py
```

**Or in config.py:**
```python
PROMPT_STYLE = os.getenv("PROMPT_STYLE", "default")
```

### Add Custom Prompts

Edit `prompts.py`:

```python
# Add your custom prompt
MY_COMPANY_PROMPT = """You are the MyCompany observability assistant.

[Your custom instructions here...]
"""

# Register it
def get_system_prompt(style: str = "default") -> str:
    prompts = {
        "default": SYSTEM_PROMPT,
        "concise": SYSTEM_PROMPT_CONCISE,
        "detailed": SYSTEM_PROMPT_DETAILED,
        "mycompany": MY_COMPANY_PROMPT,  # Add here
    }
    return prompts.get(style, SYSTEM_PROMPT)
```

### Specialized Scenario Prompts

```python
from prompts import format_scenario_prompt

# For high CPU analysis
prompt = format_scenario_prompt("high_cpu", {
    "current_metrics": cpu_data,
    "cpu_trends": trends,
    "pod_state": pods,
    "alerts": alerts
})

# Available scenarios:
# - pod_restart
# - high_cpu
# - memory_leak
# - alert_triage
```

---

## ğŸ” Troubleshooting

### Common Issues

#### 1. "GEMINI_API_KEY must be set"

**Solution:**
```bash
# Edit .env file
nano .env

# Set your key
GEMINI_API_KEY=AIza...your-key

# Verify
grep GEMINI_API_KEY .env
```

#### 2. "Kubernetes client failed"

**Solutions:**

**Minikube:**
```bash
minikube start
kubectl cluster-info
```

**Docker Desktop:**
- Enable Kubernetes in settings
- Wait for it to start
- Verify: `kubectl get nodes`

#### 3. "Prometheus unreachable"

**macOS:**
```bash
brew install prometheus
brew services start prometheus
curl http://localhost:9090/-/healthy
```

**Docker:**
```bash
docker run -d -p 9090:9090 prom/prometheus
```

#### 4. Port 8000 already in use

**Solution:**
```bash
# Change port in .env
AGENT_PORT=8080

# Or via environment
export AGENT_PORT=8080
python3 app.py
```

#### 5. Module not found errors

**Solution:**
```bash
source venv/bin/activate
pip install -r requirements.txt
```

### Setup Prometheus (if needed)

**macOS:**
```bash
brew install prometheus
brew services start prometheus
```

**Docker:**
```bash
docker run -d --name prometheus -p 9090:9090 prom/prometheus
```

**Kubernetes:**
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/prometheus
```

### Setup Loki (Optional)

**Docker:**
```bash
docker run -d --name loki -p 3100:3100 grafana/loki
```

### Debug Mode

Enable verbose logging:
```bash
export AGENT_LOG_LEVEL=DEBUG
python3 app.py
```

Check logs:
```bash
tail -f agent.log
```

---

## ğŸ“š API Reference

### Endpoints

#### POST /chat

Ask observability questions.

**Request:**
```json
{
  "question": "What is the current CPU usage?",
  "namespace": "production",
  "service": "api",
  "time_range_minutes": 15,
  "include_logs": false
}
```

**Response:**
```json
{
  "response": {
    "answer": "...",
    "tool_results": [...],
    "confidence": "high",
    "recommendations": [...]
  },
  "request_id": "uuid",
  "timestamp": "2025-12-02T..."
}
```

#### GET /health

Health check.

**Response:**
```json
{
  "status": "healthy",
  "version": "0.1.0",
  "checks": {
    "agent": true,
    "kubernetes": true,
    "prometheus": true
  }
}
```

#### GET / 

API information.

#### GET /docs

Interactive API documentation (Swagger UI).

#### GET /redoc

Alternative API documentation (ReDoc).

---

## ğŸ—ï¸ Architecture

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      User Interface (HTTP)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FastAPI Application (app.py)    â”‚
â”‚  - /chat endpoint                   â”‚
â”‚  - /health endpoint                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Orchestrator (agent.py)     â”‚
â”‚  - Tool selection                   â”‚
â”‚  - Parallel execution               â”‚
â”‚  - Context building                 â”‚
â”‚  - Gemini integration               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ K8s  â”‚  â”‚Prometh- â”‚  â”‚ Loki â”‚
â”‚ API  â”‚  â”‚  eus    â”‚  â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜
```

### Tool Selection

**Current/instant metrics:**
- Detects: "current", "now", "right now"
- Uses: `instant_query()` â†’ Single point-in-time value

**Historical metrics:**
- All other metric queries
- Uses: `metrics_query()` â†’ Time series data

### File Structure

```
k8s-observability-agent/
â”œâ”€â”€ app.py              # FastAPI application
â”œâ”€â”€ agent.py            # Agent orchestrator
â”œâ”€â”€ config.py           # Configuration
â”œâ”€â”€ models.py           # Pydantic models
â”œâ”€â”€ prompts.py          # AI prompts
â”œâ”€â”€ tools/              # Tool adapters
â”‚   â”œâ”€â”€ prometheus.py   # Metrics
â”‚   â”œâ”€â”€ k8s_state.py    # Kubernetes API
â”‚   â”œâ”€â”€ logs.py         # Loki logs
â”‚   â”œâ”€â”€ alerts.py       # Alertmanager
â”‚   â””â”€â”€ kb.py           # Knowledge base
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                # Configuration
â”œâ”€â”€ start.sh            # Quick start script
â””â”€â”€ USER_GUIDE.md       # This file
```

---

## ğŸš¢ Deployment

### Docker

```bash
# Build
docker build -t k8s-observability-agent .

# Run
docker run -d \
  -p 8000:8000 \
  --env-file .env \
  k8s-observability-agent
```

### Kubernetes

```bash
# Deploy
kubectl apply -f deploy/kubernetes.yaml

# Access
kubectl port-forward svc/observability-agent 8000:8000

# Check status
kubectl get pods -l app=observability-agent
```

See `deploy/kubernetes.yaml` for complete manifests including:
- ServiceAccount
- RBAC (ClusterRole, ClusterRoleBinding)
- Secret (for Gemini API key)
- ConfigMap
- Deployment
- Service

---

## ğŸ¯ Best Practices

### Query Optimization

**DO:**
- âœ… Be specific: "What is the current CPU usage in production?"
- âœ… Include namespace/service when relevant
- âœ… Use "current" for instant values
- âœ… Ask focused questions

**DON'T:**
- âŒ Too vague: "What's wrong?"
- âŒ Too broad: "Show everything"
- âŒ Multiple questions at once

### Prompt Customization

**DO:**
- âœ… Test prompt changes before production
- âœ… Version your prompts
- âœ… Document why you changed them
- âœ… Keep prompts focused

**DON'T:**
- âŒ Hardcode prompts in agent logic
- âŒ Change multiple prompts at once
- âŒ Make prompts overly complex

### Production Deployment

**Security:**
- ğŸ” Use secret management (Vault, AWS Secrets)
- ğŸ” Enable TLS/HTTPS
- ğŸ” Add authentication
- ğŸ” Implement rate limiting
- ğŸ” Use network policies

**Monitoring:**
- ğŸ“Š Export agent metrics
- ğŸ“Š Set up alerts
- ğŸ“Š Track response times
- ğŸ“Š Monitor API usage

---

## ğŸ“– Additional Resources

### Project Files
- **README.md** - Project overview
- **DEVELOPMENT.md** - Development guide
- **GETTING_STARTED.md** - Detailed setup
- **deploy/README.md** - Deployment guide

### Online Resources
- Gemini API: https://ai.google.dev/gemini-api/docs
- Prometheus: https://prometheus.io/docs/
- Kubernetes API: https://kubernetes.io/docs/reference/
- Loki: https://grafana.com/docs/loki/

---

## ğŸ‰ Quick Reference

### Start Agent
```bash
./start.sh                    # Interactive
python3 app.py                # Direct
```

### Test
```bash
python3 check_prerequisites.py
python3 test_current_metrics.py
curl http://localhost:8000/health
```

### Common Questions
```bash
# Current metrics
"What is the current CPU usage?"
"Show current memory for api pod"

# Troubleshooting
"Why is my pod restarting?"
"Are there any alerts firing?"

# Analysis
"Show CPU trends over last hour"
"What's causing high memory usage?"
```

### API Docs
- http://localhost:8000/docs
- http://localhost:8000/redoc

---

**Need help?** Check the troubleshooting section or review `README.md` for more details.

**Ready to start?** Run `./start.sh` and ask your first question! ğŸš€
